{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWBS6nasrWG9",
        "outputId": "c5d31379-70f9-4679-a1ee-e2e5332fd623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "\n",
        "# Install Pytorch Geometric\n",
        "# !pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.9.0.html\n",
        "# !pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.9.0.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import EllipticBitcoinDataset\n",
        "from torch_geometric.transforms import NormalizeFeatures"
      ],
      "metadata": {
        "id": "qhqZ6JdowtJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = EllipticBitcoinDataset(root='data/EllipticBitcoinDataset', transform=NormalizeFeatures())\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfBtrDPvzzXH",
        "outputId": "2fcda645-7cff-436b-94f7-5ef792f25404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_features.csv.zip\n",
            "Extracting data/EllipticBitcoinDataset/raw/elliptic_txs_features.csv.zip\n",
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_edgelist.csv.zip\n",
            "Extracting data/EllipticBitcoinDataset/raw/elliptic_txs_edgelist.csv.zip\n",
            "Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_classes.csv.zip\n",
            "Extracting data/EllipticBitcoinDataset/raw/elliptic_txs_classes.csv.zip\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EllipticBitcoinDataset()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0].edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxQsCAfGC0bl",
        "outputId": "467fd2a9-f28f-412a-f188-3ca1c8e4abf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[     0,      2,      4,  ..., 201921, 201480, 201954],\n",
              "        [     1,      3,      5,  ..., 202042, 201368, 201756]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw5w5luI0bWE",
        "outputId": "9b059c4a-b4e3-48ad-bc41-a0508cd849eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of graphs: 1\n",
            "Number of features: 165\n",
            "Number of classes: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_features = pd.read_csv('data/EllipticBitcoinDataset/raw/elliptic_txs_features.csv')\n",
        "df_edges = pd.read_csv(\"data/EllipticBitcoinDataset/raw/elliptic_txs_edgelist.csv\")\n",
        "df_classes =  pd.read_csv(\"data/EllipticBitcoinDataset/raw/elliptic_txs_classes.csv\")\n"
      ],
      "metadata": {
        "id": "nFGgvbVEKFwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "group_class = df_classes.groupby('class').count()\n",
        "plt.title(\"# of nodes per class\")\n",
        "plt.barh([ 'Illicit','Licit', 'Unknown'], group_class['txId'].values, color=['g', 'orange', 'r'] )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "Cp6pUP-tKsOT",
        "outputId": "0e8693ef-a1b8-45d2-a3dd-1005f002dc2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 3 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset[0]\n",
        "\n",
        "print(data)\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nELlAkPW0jjl",
        "outputId": "4e8d29be-2028-4126-cdef-c44588fd07e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])\n",
            "Number of nodes: 203769\n",
            "Number of edges: 234355\n",
            "Number of training nodes: 29894\n",
            "Training node label rate: 0.15\n",
            "Is undirected: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.y)\n",
        "print(dataset[0].x.shape)\n",
        "\n",
        "dataset.num_classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u4sP-TWD18V",
        "outputId": "5cd84a51-7dfb-4b6f-ca1a-1b15306a93f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 2,  ..., 1, 2, 2])\n",
            "torch.Size([203769, 165])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN using GCN"
      ],
      "metadata": {
        "id": "Mq__JetdE9JX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv #GATConv\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.out = Linear(hidden_channels, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = F.softmax(self.out(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=128)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "N2CCzPMp087l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "XThLI2BLFNnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = GCN(hidden_channels=16)\n",
        "\n",
        "#GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "\n",
        "learning_rate = 0.15\n",
        "decay = 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(),\n",
        "                             lr=learning_rate,\n",
        "                             weight_decay=decay)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test():\n",
        "      model.eval()\n",
        "      out = model(data.x, data.edge_index)\n",
        "      pred = out.argmax(dim=1)\n",
        "      test_correct = pred[data.test_mask] == data.y[data.test_mask]\n",
        "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())\n",
        "      return test_acc\n",
        "\n",
        "losses = []\n",
        "for epoch in range(0, 100):\n",
        "    loss = train()\n",
        "    losses.append(loss)\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch: {epoch}, Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouy7vM601TYC",
        "outputId": "2929d108-4b5d-44cf-af5c-6b2dc912f2ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.6879\n",
            "Epoch: 10, Loss: 0.4293\n",
            "Epoch: 20, Loss: 0.4292\n",
            "Epoch: 30, Loss: 0.4292\n",
            "Epoch: 40, Loss: 0.4293\n",
            "Epoch: 50, Loss: 0.4293\n",
            "Epoch: 60, Loss: 0.4293\n",
            "Epoch: 70, Loss: 0.4293\n",
            "Epoch: 80, Loss: 0.4293\n",
            "Epoch: 90, Loss: 0.4294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test()\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUe3YaWk20Vk",
        "outputId": "fb91187f-1581-4282-8301-dfadde5d880c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GNN using GAT**"
      ],
      "metadata": {
        "id": "PUerg9L-FVAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2=dataset[0]"
      ],
      "metadata": {
        "id": "osAjOcMMlK7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv\n",
        "\n",
        "# ... (previous code for dataset loading and model definition)\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_heads):\n",
        "        super(GAT, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        self.conv1 = GATConv(dataset.num_features, hidden_channels, heads=num_heads)\n",
        "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads)\n",
        "        self.out = Linear(hidden_channels * num_heads, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "num_heads = 4  #attention heads\n",
        "model2 = GAT(hidden_channels=128, num_heads=num_heads)\n",
        "print(model)\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model2 = model2.to(device)\n",
        "data2 = data2.to(device)\n",
        "\n",
        "learning_rate = 0.01\n",
        "decay = 5e-4\n",
        "optimizer = torch.optim.Adam(model2.parameters(),\n",
        "                             lr=learning_rate,\n",
        "                             weight_decay=decay)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "      model2.train()\n",
        "      optimizer.zero_grad()\n",
        "      out = model2(data2.x, data2.edge_index)\n",
        "      loss = criterion(out[data2.train_mask], data2.y[data2.train_mask])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss\n",
        "\n",
        "def test2():\n",
        "      model2.eval()\n",
        "      out = model2(data2.x, data2.edge_index)\n",
        "      pred = out.argmax(dim=1)\n",
        "      test_correct = pred[data2.test_mask] == data2.y[data2.test_mask]\n",
        "      test_acc = int(test_correct.sum()) / int(data2.test_mask.sum())\n",
        "      return test_acc\n",
        "\n",
        "losses = []\n",
        "for epoch in range(0, 100):\n",
        "    loss = train()\n",
        "    losses.append(loss)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n"
      ],
      "metadata": {
        "id": "W9qEaR5sVKv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-arsKvRaRqu2",
        "outputId": "ee88f683-4a88-4a16-c07a-c56c3c3925b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/IMDB'\n",
        "dataset = IMDB(path)\n",
        "data = dataset[0]\n",
        "\n",
        "data2 = sio.loadmat(f'/content/drive/MyDrive/IMDB/IMDB.mat')\n"
      ],
      "metadata": {
        "id": "nZyR0yOPNLsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54331bca-41cd-4894-c5a2-f272f42402b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os.path as osp\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.datasets import IMDB\n",
        "from torch_geometric.nn import Linear, HGTConv\n",
        "\n",
        "path = '/content/drive/MyDrive/IMDB'\n",
        "dataset = IMDB(path)\n",
        "data = dataset[0]\n",
        "\n",
        "data2 = sio.loadmat(f'/content/drive/MyDrive/IMDB/IMDB.mat')\n",
        "node_types = ['movie', 'actor']\n",
        "data1 = HeteroData()\n",
        "data1['movie'].x = torch.FloatTensor(data2['X1'])\n",
        "data1['actor'].x = torch.FloatTensor(data2['X2'])\n",
        "for i in range(data2['edge_index'].shape[1]):\n",
        "    data2['edge_index'][1, i] -= data['movie']['x'].shape[0]\n",
        "data1[('movie', 'to', 'actor')].edge_index = torch.LongTensor(data2['edge_index'])\n",
        "arr = np.copy(data2['edge_index'])\n",
        "arr[[0, 1], :] = arr[[1, 0], :]\n",
        "data1[('actor', 'to', 'movie')].edge_index = torch.LongTensor(arr)\n",
        "gnd = data2['label'][0, :]\n",
        "gnd1 = gnd[0:data['movie']['x'].shape[0]]\n",
        "gnd2 = gnd[data['movie']['x'].shape[0]:]\n",
        "a = np.sum(gnd)\n",
        "X = dict()\n",
        "for node_type in node_types:\n",
        "    X[node_type] = data1[node_type].x\n",
        "T = dict()\n",
        "T['movie'] = torch.zeros((data['movie']['x'].shape[0], 2))\n",
        "T['actor'] = torch.zeros((data['actor']['x'].shape[0], 2))\n",
        "for i in range(data['movie']['x'].shape[0]):\n",
        "    T['movie'][i, 0] = 1\n",
        "for i in range(data['actor']['x'].shape[0]):\n",
        "    T['actor'][i, 1] = 1\n",
        "\n",
        "A = dict()\n",
        "flag_movie = []\n",
        "for i in range(data.x_dict['movie'].shape[1]):\n",
        "    flag_movie.append(random.randint(1, 2))\n",
        "flag_movie = np.array(flag_movie)\n",
        "flag_actor = []\n",
        "for i in range(data.x_dict['actor'].shape[1]):\n",
        "    flag_actor.append(random.randint(1, 3))\n",
        "flag_actor = np.array(flag_actor)\n",
        "n = 0\n",
        "m = 0\n",
        "X_views = dict()\n",
        "X_views['movie'] = []\n",
        "X_views['actor'] = []\n",
        "index_movie = []\n",
        "index_actor = []\n",
        "for i in range(2):\n",
        "    while n < len(flag_movie):\n",
        "        if flag_movie[n] == i + 1:\n",
        "            index_movie.append(n)\n",
        "        n += 1\n",
        "    X_views['movie'].append(X['movie'][:, index_movie])\n",
        "    index_movie = []\n",
        "    n = 0\n",
        "for i in range(3):\n",
        "    while m < len(flag_actor):\n",
        "        if flag_actor[m] == i + 1:\n",
        "            index_actor.append(m)\n",
        "        m += 1\n",
        "    X_views['actor'].append(X['actor'][:, index_actor])\n",
        "    index_actor = []\n",
        "    m = 0\n",
        "y_dict1 = dict.copy(data.x_dict)\n",
        "y_dict1['movie'] = X_views['movie'][0]\n",
        "y_dict1['actor'] = X_views['actor'][0]\n",
        "y_dict2 = dict.copy(data.x_dict)\n",
        "y_dict2['movie'] = X_views['movie'][1]\n",
        "y_dict2['actor'] = X_views['actor'][0]\n",
        "y_dict3 = dict.copy(data.x_dict)\n",
        "y_dict3['movie'] = X_views['movie'][0]\n",
        "y_dict3['actor'] = X_views['actor'][1]\n",
        "y_dict4 = dict.copy(data.x_dict)\n",
        "y_dict4['movie'] = X_views['movie'][1]\n",
        "y_dict4['actor'] = X_views['actor'][1]\n",
        "y_dict5 = dict.copy(data.x_dict)\n",
        "y_dict5['movie'] = X_views['movie'][0]\n",
        "y_dict5['actor'] = X_views['actor'][2]\n",
        "y_dict6 = dict.copy(data.x_dict)\n",
        "y_dict6['movie'] = X_views['movie'][1]\n",
        "y_dict6['actor'] = X_views['actor'][2]\n",
        "list1 = [y_dict1, y_dict2, y_dict3, y_dict4, y_dict5, y_dict6]\n",
        "for edge_type in data.edge_index_dict.keys():\n",
        "    A[edge_type] = torch.sparse.FloatTensor(data.edge_index_dict[edge_type],\n",
        "                                            torch.LongTensor(np.ones(data.edge_index_dict[edge_type].shape[1])),\n",
        "                                            torch.Size([data[edge_type[0]]['x'].shape[0],\n",
        "                                                        data[edge_type[2]]['x'].shape[0]])).to_dense()\n",
        "\n",
        "\n",
        "class HGT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers, num_view):\n",
        "        super().__init__()\n",
        "        self.weight = torch.nn.Parameter(torch.randn(num_view), requires_grad=True)\n",
        "        self.weight_node_type = torch.nn.Parameter(torch.randn(2), requires_grad=True)\n",
        "        self.lin_dict = torch.nn.ModuleDict()\n",
        "        for node_type in data.node_types:\n",
        "            self.lin_dict[node_type] = torch.nn.ModuleList()\n",
        "            for i in range(6):\n",
        "                if i == 0:\n",
        "                    self.lin_dict[node_type].append(Linear(y_dict1[node_type].shape[1], hidden_channels))\n",
        "                if i == 1:\n",
        "                    self.lin_dict[node_type].append(Linear(y_dict2[node_type].shape[1], hidden_channels))\n",
        "                if i == 2:\n",
        "                    self.lin_dict[node_type].append(Linear(y_dict3[node_type].shape[1], hidden_channels))\n",
        "                if i == 3:\n",
        "                    self.lin_dict[node_type].append(Linear(y_dict4[node_type].shape[1], hidden_channels))\n",
        "                if i == 4:\n",
        "                    self.lin_dict[node_type].append(Linear(y_dict5[node_type].shape[1], hidden_channels))\n",
        "                if i == 5:\n",
        "                    self.lin_dict[node_type].append(Linear(y_dict6[node_type].shape[1], hidden_channels))\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = HGTConv(hidden_channels, hidden_channels, data.metadata(), num_heads, group='sum')\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.out_dict = torch.nn.ModuleDict()\n",
        "        for node_type in data.node_types:\n",
        "            self.out_dict[node_type] = Linear(hidden_channels, out_channels)\n",
        "        self.lin = torch.nn.ModuleDict()\n",
        "        for node_type in data.node_types:\n",
        "            self.lin[node_type] = Linear(out_channels, data.x_dict[node_type].shape[1])\n",
        "        self.Tlin = torch.nn.ModuleDict()\n",
        "        for node_type in data.node_types:\n",
        "            self.Tlin[node_type] = Linear(out_channels, 2)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        list3 = dict()\n",
        "        for node_type, _ in x_dict[0].items():\n",
        "            list3[node_type] = []\n",
        "        for i in range(6):\n",
        "            for node_type, x in x_dict[i].items():\n",
        "                x_dict[i][node_type] = self.lin_dict[node_type][i](x).relu_()\n",
        "\n",
        "            for conv in self.convs:\n",
        "                x_dict[i] = conv(x_dict[i], edge_index_dict)\n",
        "\n",
        "            for node_type, _ in x_dict[0].items():\n",
        "                list3[node_type].append(self.out_dict[node_type](x_dict[i][node_type]))\n",
        "\n",
        "        weight_norm = F.softmax(self.weight, dim=0)\n",
        "        weight_type = F.softmax(self.weight_node_type, dim=0)\n",
        "        Z_dict = dict()\n",
        "        A_head = dict()\n",
        "        X_head = dict()\n",
        "        t_head = dict()\n",
        "        T_head = dict()\n",
        "        for node_type, _ in x_dict[0].items():\n",
        "            Z_dict[node_type] = weight_norm[0] * list3[node_type][0] + weight_norm[1] * list3[node_type][1] + \\\n",
        "                                weight_norm[2] * list3[node_type][2] + weight_norm[3] * list3[node_type][3] + \\\n",
        "                                weight_norm[4] * list3[node_type][4] + weight_norm[5] * list3[node_type][5]\n",
        "            X_head[node_type] = self.lin[node_type](Z_dict[node_type])\n",
        "            t_head[node_type] = self.Tlin[node_type](Z_dict[node_type])\n",
        "            T_head[node_type] = torch.zeros((t_head[node_type].shape[0], t_head[node_type].shape[1]))\n",
        "            for i in range(T_head[node_type].shape[0]):\n",
        "                T_head[node_type][i, 0] = weight_type[0] * t_head[node_type][i, 0]\n",
        "                T_head[node_type][i, 1] = weight_type[1] * t_head[node_type][i, 1]\n",
        "            T_head[node_type] = F.softmax(T_head[node_type], dim=0)\n",
        "        for edge_type in edge_index_dict.keys():\n",
        "            A_head[edge_type] = torch.sigmoid(torch.mm(Z_dict[edge_type[0]], Z_dict[edge_type[2]].T))\n",
        "\n",
        "        return A_head, X_head, T_head, weight_norm, weight_type\n",
        "model = HGT(hidden_channels=64, out_channels=16, num_heads=2, num_layers=2, num_view=6)\n",
        "device = torch.device('cpu')\n",
        "data, model = data.to(device), model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.00001)\n",
        "\n",
        "\n",
        "def multiview(x, num1, num2):\n",
        "    X_hat_views = dict()\n",
        "    X_hat_views['movie'] = []\n",
        "    X_hat_views['actor'] = []\n",
        "    index_movie = []\n",
        "    index_actor = []\n",
        "    n = 0\n",
        "    m = 0\n",
        "    for i in range(num1):\n",
        "        while n < len(flag_movie):\n",
        "            if flag_movie[n] == i + 1:\n",
        "                index_movie.append(n)\n",
        "            n += 1\n",
        "        X_hat_views['movie'].append(x['movie'][:, index_movie])\n",
        "        index_movie = []\n",
        "        n = 0\n",
        "    for i in range(num2):\n",
        "        while m < len(flag_actor):\n",
        "            if flag_actor[m] == i + 1:\n",
        "                index_actor.append(m)\n",
        "            m += 1\n",
        "        X_hat_views['actor'].append(x['actor'][:, index_actor])\n",
        "        index_actor = []\n",
        "        m = 0\n",
        "    return X_hat_views\n",
        "\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    input_list = copy.deepcopy(list1)\n",
        "    A_hat, X_hat, T_hat, wX, wT = model(input_list, data.edge_index_dict)\n",
        "    loss = 0\n",
        "    loss += torch.norm(A_hat[('movie', 'to', 'actor')] - A[('movie', 'to', 'actor')])\n",
        "    loss += torch.norm(A_hat[('actor', 'to', 'movie')] - A[('actor', 'to', 'movie')])\n",
        "    for node_type in node_types:\n",
        "        loss += pow(torch.norm(T_hat[node_type] - T[node_type]), 2)\n",
        "    loss += torch.norm(X_hat['movie'] - X['movie'])\n",
        "    loss += torch.norm(X_hat['actor'] - X['actor'])\n",
        "    loss=loss/float(gnd.shape[0])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    input_list = copy.deepcopy(list1)\n",
        "    out = model(input_list, data.edge_index_dict)\n",
        "    ano_score = []\n",
        "    for i in range(data['movie']['x'].shape[0]):\n",
        "        ano_score.append(0.47 * torch.norm(out[0][('movie', 'to', 'actor')][i] - A[('movie', 'to', 'actor')][i])\n",
        "        + 0.47 * torch.norm(out[1]['movie'][i] - X['movie'][i])+0.06 * torch.norm(out[2]['movie'][i] - torch.FloatTensor(np.array(T['movie']))))\n",
        "\n",
        "    for i in range(data['actor']['x'].shape[0]):\n",
        "        ano_score.append(0.47 * torch.norm(out[0][('actor', 'to', 'movie')][i] - A[('actor', 'to', 'movie')][i])\n",
        "        + 0.47 * torch.norm(out[1]['actor'][i] - X['actor'][i])+0.06 * torch.norm(out[2]['actor'][i] - torch.FloatTensor(np.array(T['actor']))))\n",
        "\n",
        "    auc = roc_auc_score(gnd, np.array(ano_score) / max(ano_score))\n",
        "\n",
        "    return auc\n",
        "\n",
        "best_auc=0\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    auc = test()\n",
        "\n",
        "    if auc>best_auc:\n",
        "        best_auc=auc\n",
        "    print(\n",
        "    f'Epoch: {epoch:03d}, Loss: {loss:.4f}, AUC:{auc:.4f}')\n",
        "print(best_auc)"
      ],
      "metadata": {
        "id": "8xCCcqA7REzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# x axis values\n",
        "x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]\n",
        "# corresponding y axis values\n",
        "y = [0.7318,\n",
        "0.7321,\n",
        "0.7330,\n",
        "0.7345,0.7383, 0.7433, 0.7373, 0.6699, 0.6764, 0.7110, 0.7774, 0.8793, 0.9041, 0.9104, 0.9122, 0.9074, 0.8987, 0.8950, 0.8957, 0.8984, 0.9010, 0.9023, 0.9030, 0.9035, 0.9043, 0.9052, 0.9061, 0.9068, 0.9073, 0.9078, 0.9084, 0.9090, 0.9095, 0.9098, 0.9102, 0.9104, 0.9107, 0.9110, 0.9114, 0.9115, 0.9117, 0.9120, 0.9123, 0.9125, 0.9127, 0.9129, 0.9130, 0.9131, 0.9132, 0.9132, 0.9132, 0.9131, 0.9129, 0.9128, 0.9126, 0.9125, 0.9125, 0.9125, 0.9127, 0.9128]\n",
        "\n",
        "# plotting the points\n",
        "plt.plot(x, y)\n",
        "\n",
        "# naming the x axis\n",
        "plt.xlabel('x - axis')\n",
        "# naming the y axis\n",
        "plt.ylabel('y - axis')\n",
        "\n",
        "# giving a title to my graph\n",
        "\n",
        "# function to show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "MKzLiqKk0ABC",
        "outputId": "9cc442d0-8950-477b-c236-16c5273dfa32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN"
      ],
      "metadata": {
        "id": "gADAVjyozDI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a68SlBNsoY83",
        "outputId": "17fc1316-030d-49ff-82d4-3c7ede67f4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(in_channels, hidden_channels)\n",
        "        self.lin2 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin3 = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(in_channels, hidden_channels)\n",
        "        self.lin2 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin3 = nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x\n",
        "\n",
        "# class GNNExplainer:\n",
        "#     def __init__(self, generator, discriminator, device):\n",
        "#         self.generator = generator\n",
        "#         self.discriminator = discriminator\n",
        "#         self.device = device\n",
        "\n",
        "#     def train(self, data, epochs, batch_size, learning_rate):\n",
        "#         optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=learning_rate)\n",
        "#         optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "#         for epoch in range(epochs):\n",
        "#             for i in range(0, len(data), batch_size):\n",
        "#                 batch = data[i:i+batch_size]\n",
        "\n",
        "#                 # Real explanations\n",
        "#                 real_explanations = []\n",
        "#                 for graph in batch:\n",
        "#                     anomaly_node = pyg_utils.get_random_node(graph.num_nodes)\n",
        "#                     removed_edges = pyg_utils.remove_edges(graph, anomaly_node)\n",
        "#                     real_explanations.append(removed_edges)\n",
        "\n",
        "#                 # Fake explanations\n",
        "#                 fake_explanations = self.generator(batch.x.to(self.device))\n",
        "\n",
        "#                 # Train discriminator\n",
        "#                 real_discrimination = self.discriminator(real_explanations.to(self.device))\n",
        "#                 fake_discrimination = self.discriminator(fake_explanations.to(self.device))\n",
        "#                 loss_D = -torch.mean(torch.log(real_discrimination + 1e-8) + torch.log(1 - fake_discrimination + 1e-8))\n",
        "\n",
        "#                 optimizer_D.zero_grad()\n",
        "#                 loss_D.backward()\n",
        "#                 optimizer_D.step()\n",
        "\n",
        "#                 # Train generator\n",
        "#                 fake_discrimination = self.discriminator(fake_explanations.to(self.device))\n",
        "#                 loss_G = -torch.mean(torch.log(fake_discrimination + 1e-8))\n",
        "\n",
        "#                 optimizer_G.zero_grad()\n",
        "#                 loss_G.backward()\n",
        "#                 optimizer_G.step()\n",
        "\n",
        "#                 if (i + batch_size) % 100 == 0:\n",
        "#                     print(f\"Epoch {epoch}/{epochs} | Batch {i}/{len(data)} | Loss D: {loss_D.item():.4f} | Loss G: {loss_G.item():.4f}\")\n",
        "\n",
        "#     def generate_explanations(self, data):\n",
        "#         explanations = []\n",
        "#         for graph in data:\n",
        "#             explanation = self.generator(graph.x.to(self.device)).squeeze(0)\n",
        "#             explanations.append(explanation)\n",
        "\n",
        "#         return explanations\n"
      ],
      "metadata": {
        "id": "jxw53uiSz3C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "# Load the Cora dataset using PyTorch Geometric\n",
        "dataset = Planetoid(root='data', name='Cora')\n",
        "data = dataset[0]\n",
        "\n",
        "\n",
        "# Extract node labels from the data object\n",
        "node_labels = data.y\n",
        "\n",
        "# Calculate label counts\n",
        "label_counts = torch.bincount(node_labels)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Determine the target class as the label with the highest frequency\n",
        "target_class = label_counts.argmax()\n",
        "def remove_edges(edge_index, anomaly_node, device):\n",
        "    anomaly_node = torch.full((edge_index.size(1),), int(anomaly_node), dtype=torch.long, device=device)\n",
        "\n",
        "    edge_index = edge_index.to(device='cpu')\n",
        "\n",
        "    mask = (edge_index[0] != anomaly_node) & (edge_index[1] != anomaly_node)\n",
        "\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    # Filter out edges using the mask\n",
        "    filtered_edge_index = edge_index[:, mask]\n",
        "\n",
        "    return filtered_edge_index\n",
        "\n",
        "\n",
        "\n",
        "# Define graph construction function\n",
        "def construct_graph(edge_index, num_nodes):\n",
        "    # Create a PyTorch Geometric data object\n",
        "    graph = data.clone()\n",
        "    graph.edge_index = edge_index\n",
        "    return graph\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(idx):\n",
        "    # Ensure that both the graph and node features are on the same device\n",
        "\n",
        "    # Extract edge information from the data object\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Create a PyTorch Geometric data object from the edge information\n",
        "    graph = construct_graph(edge_index, num_nodes=data.num_nodes)\n",
        "\n",
        "    # Label graph as normal or anomalous\n",
        "    label = 1 if data.y[idx] == target_class else 0  # Use target_class instead of data.target_class\n",
        "\n",
        "    if label == 1:\n",
        "        # Generate real explanation by removing edges\n",
        "        anomaly_node = torch.randint(graph.num_nodes, (1,))\n",
        "\n",
        "        anomaly_node = anomaly_node.to(device)  # Move anomaly_node to the CUDA device\n",
        "        removed_edges = remove_edges(graph.edge_index, anomaly_node, device)\n",
        "        real_explanations.append(removed_edges)\n",
        "\n",
        "        # Construct modified graph\n",
        "        modified_edge_index = modify_edge_information(edge_index)\n",
        "        modified_graph = construct_graph(modified_edge_index, num_nodes=data.num_nodes).to(device)\n",
        "\n",
        "        return None, modified_graph, label\n",
        "\n",
        "    return None, graph, label\n",
        "# Define a function to modify the edge information for the modified graph\n",
        "def modify_edge_information(edge_index):\n",
        "    # Implement your logic to modify the edge information here\n",
        "    # This is a placeholder, you need to customize it based on your requirements\n",
        "    modified_edge_index = edge_index.clone()\n",
        "    return modified_edge_index\n",
        "\n",
        "# Prepare data for training\n",
        "real_explanations = []\n",
        "fake_explanations = []\n",
        "\n",
        "for i in range(data.num_edges):\n",
        "    features, graph, label = preprocess_data(i)\n",
        "\n",
        "    if label == 1:\n",
        "        # Generate real explanation by removing edges\n",
        "        anomaly_node = torch.randint(graph.num_nodes, (1,)).item()\n",
        "\n",
        "        removed_edges = remove_edges(graph.edge_index, anomaly_node,device)\n",
        "        real_explanations.append(removed_edges)\n",
        "\n",
        "        # Generate fake explanation using the GAN\n",
        "        fake_explanation = generator(graph.ndata['feat'].to(device)).squeeze(0)\n",
        "        fake_explanations.append(fake_explanation)\n",
        "\n",
        "\n",
        "# Train the GAN explainer\n",
        "generator = Generator(in_channels=features.shape[0], out_channels=data.num_nodes * data.num_nodes)\n",
        "discriminator = Discriminator(in_channels=data.num_nodes * data.num_nodes, hidden_channels=128)\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "gnn_explainer = GNNExplainer(generator, discriminator, device)\n",
        "gnn_explainer.train(data=processed_data, epochs=10, batch_size=32, learning_rate=0.001)\n",
        "\n",
        "# Generate explanations for new data points\n",
        "new_features, new_graph, new_label = preprocess_data(100)  # Replace 100 with the index of the new data point\n",
        "new_explanation = gnn_explainer.generate_explanations([new_graph])[0]\n",
        "\n",
        "# Evaluate the explanation\n",
        "# ...  # Replace ... with your explanation evaluation code\n"
      ],
      "metadata": {
        "id": "zh5wH6cE0LyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "dataset = Planetoid(root='data', name='Cora')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = dataset[0]\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TZmlpGZYrj0",
        "outputId": "0765fa99-cde0-4693-c512-2ebb90f5d28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNExplainer:\n",
        "    def __init__(self, generator, discriminator, device):\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.device = device\n",
        "\n",
        "    def train(self, data, epochs, batch_size, learning_rate):\n",
        "        optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=learning_rate)\n",
        "        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=learning_rate)\n",
        "\n",
        "        for epoch in range(1):\n",
        "            for i in range(0, 1, batch_size):\n",
        "                batch = data[i:i+batch_size]\n",
        "\n",
        "                # Real explanations\n",
        "                real_explanations = []\n",
        "                for graph in batch:\n",
        "                    anomaly_node = torch.randint(graph.num_nodes, (1,)).item()\n",
        "                    # Assuming graph has 'edge_index' attribute\n",
        "                    mask = (graph.edge_index[0] != anomaly_node) & (graph.edge_index[1] != anomaly_node)\n",
        "                    removed_edges = graph.edge_index[:, mask]\n",
        "                    real_explanations.append(removed_edges)\n",
        "\n",
        "                # Fake explanations\n",
        "                fake_explanations = self.generator(batch.x.to(self.device))\n",
        "\n",
        "                # Train discriminator\n",
        "                real_discrimination = self.discriminator(real_explanations.to(self.device))\n",
        "                fake_discrimination = self.discriminator(fake_explanations.to(self.device))\n",
        "                loss_D = -torch.mean(torch.log(real_discrimination + 1e-8) + torch.log(1 - fake_discrimination + 1e-8))\n",
        "\n",
        "                optimizer_D.zero_grad()\n",
        "                loss_D.backward()\n",
        "                optimizer_D.step()\n",
        "\n",
        "                # Train generator\n",
        "                fake_discrimination = self.discriminator(fake_explanations.to(self.device))\n",
        "                loss_G = -torch.mean(torch.log(fake_discrimination + 1e-8))\n",
        "\n",
        "                optimizer_G.zero_grad()\n",
        "                loss_G.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "\n",
        "                print(f\"Epoch {epoch}/{epochs} | Batch {i}/{len(data)} | Loss D: {loss_D.item():.4f} | Loss G: {loss_G.item():.4f}\")\n",
        "\n",
        "    def generate_explanations(self, data):\n",
        "        explanations = []\n",
        "\n",
        "        for batch in data_loader:\n",
        "            batch = batch.to(self.device)\n",
        "\n",
        "            # Fake explanations\n",
        "            fake_explanations = self.generator(batch.x)\n",
        "\n",
        "            fake_explanations = fake_explanations.to_sparse()\n",
        "\n",
        "            # Train discriminator\n",
        "            real_discrimination = self.discriminator(batch.edge_index)\n",
        "            fake_discrimination = self.discriminator(fake_explanations.indices())\n",
        "\n",
        "            anomaly_scores = torch.sigmoid(fake_discrimination)\n",
        "\n",
        "            threshold = 0.5  # Adjust this threshold based on your needs\n",
        "            anomaly_indices = (anomaly_scores > threshold).nonzero()\n",
        "\n",
        "            # Extract explanations based on anomaly indices\n",
        "            for idx in anomaly_indices:\n",
        "                anomaly_node = fake_explanations.indices()[idx]\n",
        "                removed_edges = pyg_utils.remove_edges(batch.edge_index, anomaly_node)\n",
        "                explanations.append(removed_edges)\n",
        "\n",
        "        return explanations\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(in_channels=data.num_features, out_channels=data.num_nodes, hidden_channels=16)\n",
        "discriminator = Discriminator(in_channels=data.num_nodes, hidden_channels=16)\n",
        "\n",
        "# Initialize GNNExplainer\n",
        "gnn_explainer = GNNExplainer(generator, discriminator, device)\n",
        "\n",
        "# Training loop (call train method)\n",
        "gnn_explainer.train(dataset, epochs=10, batch_size=32, learning_rate=0.001)\n",
        "\n",
        "# Generate explanations for the entire dataset\n",
        "# explanations = gnn_explainer.generate_explanations(data_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "IsyCfMv5YTuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DONT RUN\n",
        "\n",
        "# Load the Cora dataset using PyTorch Geometric\n",
        "# dataset = Planetoid(root='data', name='Cora')\n",
        "# data = dataset[0]\n",
        "\n",
        "# Extract node labels from the data object\n",
        "node_labels = data.y\n",
        "\n",
        "# Calculate label counts\n",
        "label_counts = torch.bincount(node_labels)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Determine the target class as the label with the highest frequency\n",
        "target_class = label_counts.argmax()\n",
        "\n",
        "def remove_edges(edge_index, anomaly_node, device):\n",
        "    # Ensure anomaly_node has the same shape as edge_index\n",
        "    anomaly_node = torch.full((edge_index.size(1),), int(anomaly_node), dtype=torch.long, device=device)\n",
        "\n",
        "    # Move edge_index to the CPU for element-wise comparisons\n",
        "    edge_index = edge_index.to(device)\n",
        "\n",
        "    # Create a mask to identify edges involving the anomaly node\n",
        "    mask = (edge_index[0] != anomaly_node) & (edge_index[1] != anomaly_node)\n",
        "\n",
        "    # Move the mask back to the CUDA device for subsequent operations\n",
        "    mask = mask.to(device)\n",
        "\n",
        "    # Filter out edges using the mask\n",
        "    filtered_edge_index = edge_index[:, mask]\n",
        "\n",
        "    return filtered_edge_index\n",
        "\n",
        "# Define graph construction function\n",
        "def construct_graph(edge_index, num_nodes):\n",
        "    # Create a PyTorch Geometric data object\n",
        "    graph = data.clone()\n",
        "    graph.edge_index = edge_index\n",
        "    return graph\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(idx):\n",
        "    # Ensure that both the graph and node features are on the same device\n",
        "\n",
        "    # Extract edge information from the data object\n",
        "    edge_index = data.edge_index\n",
        "\n",
        "    # Create a PyTorch Geometric data object from the edge information\n",
        "    graph = construct_graph(edge_index, num_nodes=data.num_nodes)\n",
        "\n",
        "    # Label graph as normal or anomalous\n",
        "    label = 1 if data.y[idx] == target_class else 0  # Use target_class instead of data.target_class\n",
        "\n",
        "    if label == 1:\n",
        "        # Generate real explanation by removing edges\n",
        "        anomaly_node = torch.randint(graph.num_nodes, (1,))\n",
        "\n",
        "        anomaly_node = anomaly_node.to(device)  # Move anomaly_node to the CUDA device\n",
        "        removed_edges = remove_edges(graph.edge_index, anomaly_node, device)\n",
        "        real_explanations.append(removed_edges)\n",
        "\n",
        "        # Construct modified graph\n",
        "        modified_edge_index = modify_edge_information(edge_index)\n",
        "        modified_graph = construct_graph(modified_edge_index, num_nodes=data.num_nodes).to(device)\n",
        "\n",
        "        return None, modified_graph, label\n",
        "\n",
        "    return None, graph, label\n",
        "# Define a function to modify the edge information for the modified graph\n",
        "def modify_edge_information(edge_index):\n",
        "    # Implement your logic to modify the edge information here\n",
        "    # This is a placeholder, you need to customize it based on your requirements\n",
        "    modified_edge_index = edge_index.clone()\n",
        "    return modified_edge_index\n",
        "\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(in_channels=data.num_features, out_channels=data.num_nodes * data.num_nodes, hidden_channels=64)\n",
        "discriminator = Discriminator(in_channels=data.num_nodes * data.num_nodes,hidden_channels=128)  # Fix: Use hidden_channels instead of in_channels\n",
        "\n",
        "# Initialize GNNExplainer\n",
        "gnn_explainer = GNNExplainer(generator, discriminator, device)\n",
        "\n",
        "# Prepare data for training (replace processed_data with your actual training data)\n",
        "real_explanations = []\n",
        "fake_explanations = []\n",
        "\n",
        "for i in range(data.num_edges):\n",
        "    features, graph, label = preprocess_data(i)\n",
        "\n",
        "    if label == 1:\n",
        "        # Generate real explanation by removing edges\n",
        "        anomaly_node = torch.randint(graph.num_nodes, (1,)).item()\n",
        "\n",
        "        removed_edges = remove_edges(graph.edge_index, anomaly_node, device)\n",
        "        real_explanations.append(removed_edges)\n",
        "\n",
        "        # Generate fake explanation using the GAN\n",
        "        fake_explanation = generator(data['x'].to(device)).squeeze(0)\n",
        "        fake_explanations.append(fake_explanation)\n",
        "\n",
        "# Train the GAN explainer\n",
        "gnn_explainer.train(data=processed_data, epochs=10, batch_size=32, learning_rate=0.001)\n",
        "\n",
        "# Generate explanations for new data points\n",
        "new_features, new_graph, new_label = preprocess_data(100)  # Replace 100 with the index of the new data point\n",
        "new_explanation = gnn_explainer.generate_explanations([new_graph])[0]\n"
      ],
      "metadata": {
        "id": "5pDkH9HXYh3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch_geometric"
      ],
      "metadata": {
        "id": "jcGEoxJVJdq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='data', name='Cora')\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Custom collate function\n",
        "def collate(data_list):\n",
        "    batch = Data()\n",
        "\n",
        "    # Extract necessary information from Data objects\n",
        "    batch.x = [data.x for data in data_list]\n",
        "    batch.edge_index = [data.edge_index for data in data_list]\n",
        "\n",
        "    return batch\n",
        "\n",
        "# Create DataLoader with custom collate function\n",
        "data_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create instances of Generator and Discriminator\n",
        "generator = Generator(in_channels=data.num_features, out_channels=data.num_nodes * data.num_nodes, hidden_channels=64)\n",
        "discriminator = Discriminator(in_channels=data.num_nodes * data.num_nodes,hidden_channels=128)  # Fix: Use hidden_channels instead of in_channels\n",
        "\n",
        "# Create an instance of GNNExplainer\n",
        "gnn_explainer = GNNExplainer(generator, discriminator, device)\n"
      ],
      "metadata": {
        "id": "Rd46qVq7Lv2t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}